> Parallel computer architecture refers to the design and organization of computer systems that can perform multiple computations simultaneously, often to improve performance and efficiency. This approach contrasts with traditional, serial computing where tasks are processed one at a time.


### **Parallel Computer Architecture**

1. **[Parallel Computer Architecture](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Parallel%20Computer%20Architecture.md)**  
   Introduction to the basics of parallel computer architecture, including key concepts and the motivation for parallel systems.

2. **[Models](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Models.md)**  
   Describes various models for parallel computation, such as shared memory, distributed memory, and hybrid models.

3. **[Processor in Parallel Systems](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Processor%20in%20Parallel%20Systems.md)**  
   Discusses processor types used in parallel systems and their role in ensuring efficient execution of parallel tasks.

4. **[Cache Coherence and Synchronization](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Cache%20Coherence%20and%20Synchronization.md)**  
   Explains mechanisms for maintaining data consistency across multiple caches in a parallel system, and methods to synchronize processes.

5. **[Multiprocessors and Multicomputers](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Multiprocessors%20and%20Multicomputers.md)**  
   Compares multiprocessor systems (shared memory) and multicomputers (distributed memory) in terms of architecture and performance.

6. **[Hardware Software Tradeoffs](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Hardware%20Software%20Tradeoffs.md)**  
   Discusses the design trade-offs between hardware complexity and software overhead in parallel systems.

7. **[Interconnection Network Design](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Interconnection%20Network%20Design.md)**  
   Explores the design of interconnection networks used to connect processors, including topologies like mesh, hypercube, and bus.

8. **[Latency Tolerance](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Latency%20Tolerance.md)**  
   Describes techniques for minimizing the impact of latency on parallel computation, such as prefetching and multithreading.

---

### **Parallel Algorithms**

9. **[Parallel Algorithm](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Parallel%20Algorithm.md)**  
   Introduction to parallel algorithms, their importance, and the challenges in their design and implementation.

10. **[Analysis](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Analysis.md)**  
    Discusses the analysis of parallel algorithms in terms of time complexity, speedup, and efficiency.

11. **[Parallel Algorithm - Models](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Parallel%20Algorithm%20-%20Models.md)**  
    Explains the models used to design parallel algorithms, such as PRAM (Parallel Random Access Machine).

12. **[Parallel Random Access Machines](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Parallel%20Random%20Access%20Machines.md)**  
    Details the PRAM model, including its types (EREW, CREW, CRCW) and their applications.

13. **[Parallel Algorithm - Structure](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Parallel%20Algorithm%20-%20Structure.md)**  
    Discusses the structural organization of parallel algorithms, focusing on decomposition and task distribution.

14. **[Parallel Algorithm - Design Techniques](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Parallel%20Algorithm%20-%20Design%20Techniques.md)**  
    Explores various techniques for designing parallel algorithms, such as divide-and-conquer and pipelining.

15. **[Parallel Algorithm - Matrix Multiplication](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Parallel%20Algorithm%20-%20Matrix%20Multiplication.md)**  
    Focuses on parallel matrix multiplication algorithms and their optimization for performance.

16. **[Parallel Sorting Algorithms](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Parallel%20Algorithm%20-%20Sorting.md)**  
    Discusses sorting algorithms adapted for parallel systems, such as bitonic and quicksort.

17. **[Parallel Search Algorithm](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Parallel%20Search%20Algorithm.md)**  
    Explains parallel approaches to search problems, including linear and binary search optimizations.

18. **[Graph Algorithm](https://github.com/aw-junaid/Computer-Science/blob/main/Parallel%20and%20Distributed%20Computing/Parallel%20Computer%20Architecture/course/Graph%20Algorithm.md)**  
    Covers graph-based parallel algorithms for problems like shortest paths, spanning trees, and connectivity.



